\documentclass[12pt,t]{beamer}
\usepackage{graphicx}
\setbeameroption{hide notes}
\setbeamertemplate{note page}[plain]
\usepackage{listings}

\input{LaTeX/header.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% end of header
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% title info
\title{1: Intro to Reproducible Research}
\author{}
\date{\href{https://bit.ly/SISBID3}{\tt \color{foreground} bit.ly/SISBID3}}

\begin{document}

% title slide
{
\setbeamertemplate{footline}{} % no page number here
\frame{
  \titlepage
  \note{This is the introductory lecture for the SISBID Workshop on
    Reproducible Research.

A minimal standard for data analysis and other scientific computations
is that they be {\color{nhilit} reproducible}: that the code and data are assembled
in a way so that another group can re-create all of the results (e.g.,
the figures in a paper). The importance of such reproducibility is now
widely recognized, but it is not so widely practiced as it should be,
in large part because many computational scientists (and particularly
statisticians) have not fully adopted the required tools for
reproducible research.
} }


\begin{frame}[fragile,c]{}

\begin{center}
\begin{minipage}[c]{9.3cm}
\begin{semiverbatim}
\lstset{basicstyle=\normalsize}
\begin{lstlisting}[linewidth=9.3cm]
 Karl -- this is very interesting,
 however you used an old version of
 the data (n=143 rather than n=226).

 I'm really sorry you did all that
 work on the incomplete dataset.

 Bruce
\end{lstlisting}
\end{semiverbatim}
\end{minipage}
\end{center}

\note{This is an edited version of an email I got from a collaborator,
  in response to an analysis report that I had sent him.

  I try to always include some brief data summaries at the start of
  such reports. By doing so, he immediately saw that I had an old
  version of the data.

  Because I'd set things up carefully, I could just substitute in the
  newer dataset, type ``{\tt make}'', and get the revised report.

  This is a reproducibility success story. But it took me a long
  time to get to this point.
}
\end{frame}




\begin{frame}[c]{}


\centering
\Large

Reproducible

\bigskip

\onslide<2->{{\color{lolit} vs.}}

\bigskip

\only<1|handout 0>{{\color{background} invisible text}}
\only<2>{Replicable}
\only<3 | handout 0>{Correct}

\note{Computational work is
  {\color{nhilit} reproducible} if one can take the data and code and produce
  the same set of results. {\color{nhilit} Replicable} is more stringent: can
  someone repeat the experiment and get the same results?

  Reproducibility is a minimal standard. That something is
  reproducible doesn't imply that it is correct. The code may have bugs. The
  methods may be poorly behaved. There could be experimental
  artifacts.

  (But reproducibility is probably correlated with correctness.)

  Note that some scientists say replicable for what I call
  reproducible, and vice versa.
}
\end{frame}



\begin{frame}{Levels of quality}


\vspace{24pt}

\bi
\itemsep12pt
\item Are the tables and figures reproducible from the code and data?
\item Does the code actually do what you think it does?
\item In addition to {\color{hilit} what} was done, is it clear
  {\color{hilit} why} it was done?
  \bi
  \item[] (e.g., how were parameter settings chosen?)
  \ei
\item Can the code be used for other data?
\item Can you extend the code to do other things?
\ei

\note{Reproducibility is not black and white. And the ideal is hard to
  achieve.
}
\end{frame}



\begin{frame}{Basic principles}


\vspace{24pt}

\bi
\itemsep12pt
\item Everything via code
\item Everything automated
    \bi
    \item[] Workflow and dependencies clearly documented
    \ei
\item Get the data in the most-raw form possible
\item Get any/all data and meta-data possible
\item Keep track of the {\color{hilit} provenance} of all data files
\item Be self-sufficient
\ei

\note{Pointing and clicking is not reproducible. Ideally, you press
  just one button.

Make sure you have all of the data and that you know exactly where it
came from.

But what is {\color{nhilit} raw} data? How far back should you go?
Data that I get from collaborators has usually gone through a
considerable amount of pre-processing. Should we have captured that,
in order for the work to be considered reproducible?

If your collaborator asks, ``In what form would you like the data?''
you should respond, ``In its current form.''
}
\end{frame}

\begin{frame}{Why do we care?}

\vspace{24pt}

\bi
\itemsep12pt
\item Avoid embarrassment
\item More likely correct
\item Save time, in the long run
\item Greater potential for extensions; higher impact
\ei

\note{Doing things properly (writing clear, documented, well-tested
  code) is time consuming, but it could save you a ton of aggravation
  down the road.  Ultimately, you'll be more efficient, and your work
  will have greater impact.

Your code and analyses will be easier to debug, maintain, and extend.
}
\end{frame}


\begin{frame}[c]{}

\centering
\large
Your closest collaborator is you six months ago, but you
don't reply to emails.
\note{I heard this from Paul Wilson, UW-Madison.


  I think he got it from a tweet by Karen Cranston: {\tt
    http://bit.ly/motivate\_git}
}
\end{frame}


\begin{frame}{What could go wrong?}

\vspace{24pt}

\bi
\itemsep12pt
\item "The attached is similar to the code we used."
\item "Where did this data file come from?!"
\item "Can you repeat the analysis, omitting subject X?"
\item "This part of your script is now giving an error."
\ei

\note{If you've not heard any of these things, it's just a matter of
  time.
}
\end{frame}


\begin{frame}{Need to avoid}


\vspace{24pt}

\bi
\itemsep12pt
\item Open a file to extract as CSV
\item Open a data file to do even a slight edit
\item Paste results into the text of a manuscript
\item Copy-paste-edit tables
\item Copy-paste-adjust figures
\ei

\note{If you do anything ``by hand'' once, you'll have to do it 100
  times.
}
\end{frame}

\begin{frame}{Basic tools}


\vspace{24pt}

\bi
\itemsep12pt
\item Automation with Make
\item Unix command line
\item Latex and Markdown
\item Knitr
\item Version control with git
\item R packages
\item Python (or Ruby or Perl)
\ei

\note{These are the basic tools that I think are important for
  reproducible computational research; they form the core topics for
  the course.

  Make is for automation and for documenting dependencies. For
  reproducibility, the command line is your best friend. Latex and
  Markdown allow preparation of beautiful documents without pointing
  or clicking. Knitr is for combining code and text; knitr and make
  are the key tools for reproducibility. Version control isn't
  strictly necessary for reproducibility, but once you get the hang of
  it, you'll never go back. R's packaging system is among its best
  features. A scripting language like Python is invaluable for
  manipulating data files. Many things that are awkward in R are easy
  in Python.
}
\end{frame}


\begin{frame}{Other topics}

\vspace{24pt}

\bi
\itemsep12pt
\item Organizing projects
\item Writing clear code
\item Don't Repeat Yourself (DRY)
\item Testing and debugging
\item Handling big jobs
\item Licenses; human subjects data
\ei

\note{We'll also cover all of these things.

The organization of the data and code for a project is a major
determinant of whether others will be able to make sense of it.
Good code is not just correct but is clearly written. Code is easier
to maintain and understand if it is modular. Adding good tests will
help you to find problems in your code earlier rather than later. But
you'll spend a lot of time debugging, so we should talk about
debugging strategies. Big computational jobs (particularly big
computer simulations) raise additional issues; reproducibility is
especially tricky. Finally, code that you distribute should be
licensed. And if you're working with data on human subjects, you
need to be extra careful.
}
\end{frame}


\begin{frame}{Don't Repeat Yourself}

\vspace{24pt}

\bi
\itemsep12pt
\item In code, in documentation, etc.
\item Repeated bits of code are harder to maintain
    \bi
    \item[] Write a function
    \ei
\item Use documentation systems like Roxygen2
    \bi
    \item[] Documentation in just one place
    \ei
\item Make use of others' code
\ei

\note{DRY is among the more important concepts/techniques.

For example, I helped organize a meeting
in Madison in 2013. The program book and website both drew
information from a single basic source. Change that one document and
both the program and web site are updated.

My R/qtl package is an {\color{nhilit} anti}-example.
}
\end{frame}

\begin{frame}{This course}

\vspace{24pt}

\bi
\itemsep18pt
\item Brief intro to various tools and concepts
\item Try everything out as we go along
    \bi
    \item[] Ask questions!
    \ei
\item I don't know everything
    \bi
    \item[] Make suggestions!
    \ei
\item Project
    \bi
    \item Write a bit of R code
    \item Use version control
    \item Make it an R package
    \item Write a vignette
    \ei
\ei

\note{About this course: I'm trying to get you started; pointing you
  in the right direction. But I don't know everything, and I don't
  always do things in the most efficient way possible: please offer me
  suggestions!

  We won't have time for a comprehensive introduction to the tools.
  My main goal is to convince you of their importance: to motivate you
  to adopt them.
}
\end{frame}


\begin{frame}[c]{}

\begin{center}
\large
The most important tool is the {\hilit mindset},\\
when starting, that the end product \\
will be reproducible.
\end{center}

\hfill
{\lolit
{\textendash} \href{http://odin.mdacc.tmc.edu/~kabaggerly/}{Keith Baggerly}
}

\note{So true. Desire for reproducibility is step one.
}
\end{frame}



\begin{frame}{Automation with GNU Make}

\vspace{24pt}

\bi
\itemsep12pt
\item {\tt Make} is for more than just compiling software
\item The {\color{hilit} essence} of what we're trying to do
\item Automates a workflow
\item Documents the workflow
\item Documents the dependencies among data files, code
\item Re-runs only the necessary code, based on what has changed
\ei


\note{People usually think of Make as a tool for automating the
  compilation of software, but it can be used much more generally.

  To me, Make is the essential tool for reproducible research:
  automation plus the documentation of dependencies and workflows.
}
\end{frame}


\begin{frame}[fragile]{Example {\tt Makefile}}

\begin{semiverbatim}
\begin{lstlisting}
# Example Makefile for a paper
mypaper.pdf: mypaper.bib mypaper.tex Figs/fig1.pdf Figs/fig2.pdf
    pdflatex mypaper
    bibtex mypaper
    pdflatex mypaper
    pdflatex mypaper

# cd R has to be on the same line as R CMD BATCH
Figs/fig1.pdf: R/fig1.R
    cd R;R CMD BATCH fig1.R fig1.Rout

Figs/fig2.pdf: R/fig2.R
    cd R;R CMD BATCH fig2.R fig2.Rout
\end{lstlisting}
\end{semiverbatim}

\note{You can get really fancy with make, but this example shows you
  the basics.

  Records look like {\tt target: dependencies} and are followed by a
  set of lines of code for creating the target from the
  dependencies. Those lines of code must start with a tab character
  ({\color{nvhilit} not} spaces), and if you need to change
  directories, you have to do that on the same line as the command.

  If you type {\tt make} (or {\tt make Makefile}), the {\tt
  mypaper.pdf} file will be created; but first, any dependencies
  will be updated, if necessary, based on the time the files were last
  modified.

  So, for example, if {\tt fig1.R} had been edited, then the commands
  to construct {\tt fig1.pdf} would be constructed, followed by the
  commands to construct {\tt mypaper.pdf}.
}
\end{frame}



\begin{frame}[fragile]{Fancier example}

\begin{semiverbatim}
\begin{lstlisting}
FIG_DIR = Figs

mypaper.pdf: mypaper.tex ${FIG_DIR}/fig1.pdf ${FIG_DIR}/fig2.pdf
    pdflatex mypaper

# One line for both figures
${FIG_DIR}/%.pdf: R/%.R
    cd R;R CMD BATCH $(<F)

# Use "make clean" to remove the PDFs
clean:
    rm *.pdf Figs/*.pdf
\end{lstlisting}
\end{semiverbatim}

\note{As I said, you can get really fancy with GNU Make.

  Use variables for directory names or compiler flags. (This example
  is not a good one.)

  Use pattern rules and automatic variables to avoid repeating
  yourself. With {\tt \%}, we have one line covering both
  {\tt fig1.pdf} and {\tt fig2.pdf}. The {\tt \$(<F)}
  is the file part of
  the first dependency.

  Look at the manual for make and the many online tutorials, such as
  the one from Software Carpentry.
}
\end{frame}



\begin{frame}[fragile]{How do you use make?}

\vspace{6pt}

{\small
\bi
\item If you name your make file {\tt Makefile}, then just go into the
directory containing that file and type {\tt \color{hilit} make}

\item If you name your make file {\tt something.else}, then type \\
{\tt \color{hilit} make -f something.else}

\item Actually, the commands above will build the {\color{vhilit} first}
  target listed in the make file. So I'll often include something like
  the following.

\begin{quote}
{\tt \color{hilit} all: target1 target2 target3}
\end{quote}

  Then typing {\tt \color{hilit} make all} (or just {\tt
    \color{hilit} make}, if {\tt \color{hilit} all} is listed
  first in the file) will build all of those
  things.

\item To be build a specific target, type {\tt \color{hilit} make target}.
  For example, {\tt \color{hilit} make Figs/fig1.pdf}
\ei
}

\note{I can't believe that I forgot to explain this the first time
  I gave this lecture.
}
\end{frame}

\end{document}
